# ğŸ›°ï¸ AtlasField

**AI-powered satellite crop monitoring for agriculture and forestry**

AtlasField is a SaaS platform that leverages satellite imagery (Sentinel-1 & Sentinel-2) and AI to help farmers and foresters monitor their fields, predict yields, and receive actionable insights.

![Next.js](https://img.shields.io/badge/Next.js-15-black?logo=next.js)
![FastAPI](https://img.shields.io/badge/FastAPI-0.115-009688?logo=fastapi)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15-336791?logo=postgresql)
![Docker](https://img.shields.io/badge/Docker-Ready-2496ED?logo=docker)

## âœ¨ Features

- ğŸ—ºï¸ **Interactive Map** - Draw and manage field boundaries with MapLibre GL
- ğŸ“Š **Satellite Analysis** - NDVI, RVI, and multi-sensor fusion from Sentinel Hub
- ğŸ¤– **AI Assistant** - Get personalized agricultural advice powered by Google Gemini
- ğŸ”” **Smart Alerts** - Automated notifications for crop health issues
- ğŸ“ˆ **Yield Predictions** - Machine learning-based harvest forecasting
- ğŸŒ± **Biomass Estimation** - Carbon sequestration monitoring

## ğŸ—ï¸ Project Structure

```
AtlasField/
â”œâ”€â”€ backend/                 # FastAPI Backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ routers/        # API endpoints
â”‚   â”‚   â”œâ”€â”€ services/       # Business logic
â”‚   â”‚   â”œâ”€â”€ config.py       # Settings
â”‚   â”‚   â”œâ”€â”€ database.py     # PostgreSQL connection
â”‚   â”‚   â”œâ”€â”€ models.py       # SQLAlchemy models
â”‚   â”‚   â””â”€â”€ schemas.py      # Pydantic schemas
â”‚   â”œâ”€â”€ .env                # Backend environment
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ frontend/               # Next.js Frontend
â”‚   â”œâ”€â”€ app/               # App router pages
â”‚   â”œâ”€â”€ components/        # React components
â”‚   â”œâ”€â”€ lib/              # Utilities & API client
â”‚   â”œâ”€â”€ .env.local        # Frontend environment
â”‚   â”œâ”€â”€ Dockerfile        # Production
â”‚   â””â”€â”€ Dockerfile.dev    # Development
â”œâ”€â”€ docker-compose.yml     # Production setup
â””â”€â”€ docker-compose.dev.yml # Development setup
```

## ğŸš€ Quick Start

### Prerequisites

- [Docker](https://docs.docker.com/get-docker/) & Docker Compose
- Or for local development:
  - Node.js 20+
  - Python 3.11+
  - PostgreSQL 15+

### Option 1: Docker (Recommended)

**1. Clone the repository**
```bash
git clone https://github.com/yourusername/atlasfield.git
cd atlasfield
```

**2. Configure environment variables**

Copy the example files and edit them:
```bash
# Backend
cp backend/.env.example backend/.env

# Frontend
cp frontend/.env.example frontend/.env.local
```

**3. Start with Docker Compose**

For development (with hot reload):
```bash
docker-compose -f docker-compose.dev.yml up --build
```

For production:
```bash
docker-compose up --build
```

**4. Access the application**
- ğŸŒ Frontend: http://localhost:3000
- ğŸ”Œ Backend API: http://localhost:8000
- ğŸ“š API Docs: http://localhost:8000/docs

---

### Option 2: Local Development

**1. Start PostgreSQL**

You can use Docker just for the database:
```bash
docker run -d \
  --name atlasfield-db \
  -e POSTGRES_USER=atlasfield \
  -e POSTGRES_PASSWORD=atlasfield \
  -e POSTGRES_DB=atlasfield \
  -p 5432:5432 \
  postgres:15-alpine
```

**2. Setup Backend**
```bash
cd backend

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# or: .venv\Scripts\activate  # Windows

# Install dependencies
pip install -r requirements.txt

# Configure environment
cp .env.example .env
# Edit .env and set DATABASE_URL to localhost:
# DATABASE_URL=postgresql+asyncpg://atlasfield:atlasfield@localhost:5432/atlasfield

# Start the server
uvicorn app.main:app --reload --port 8000
```

**3. Setup Frontend**
```bash
cd frontend

# Install dependencies
npm install

# Configure environment
cp .env.example .env.local
# Edit .env.local if needed

# Start development server
npm run dev
```

## âš™ï¸ Configuration

### Backend Environment Variables (`backend/.env`)

| Variable | Description | Required |
|----------|-------------|----------|
| `DATABASE_URL` | PostgreSQL connection string | âœ… |
| `SECRET_KEY` | JWT signing key (min 32 chars) | âœ… |
| `SENTINEL_HUB_CLIENT_ID` | Copernicus Data Space client ID | âŒ |
| `SENTINEL_HUB_CLIENT_SECRET` | Copernicus Data Space secret | âŒ |
| `GEMINI_API_KEY` | Google Gemini API key | âŒ |
| `CORS_ORIGINS` | Allowed origins (comma-separated) | âœ… |

### Frontend Environment Variables (`frontend/.env.local`)

| Variable | Description | Required |
|----------|-------------|----------|
| `NEXT_PUBLIC_API_URL` | Backend API URL | âœ… |
| `NEXTAUTH_URL` | Frontend URL for NextAuth | âœ… |
| `NEXTAUTH_SECRET` | NextAuth encryption key | âœ… |
| `NEXT_PUBLIC_MAPTILER_KEY` | MapTiler API key for maps | âŒ |

### Getting API Keys

- **Sentinel Hub**: Register at [Copernicus Data Space](https://dataspace.copernicus.eu/)
- **Gemini**: Get your key at [Google AI Studio](https://makersuite.google.com/app/apikey)
- **MapTiler**: Register at [MapTiler](https://www.maptiler.com/) (100k free tiles/month)

## ï¿½ï¸ Database Migrations

AtlasField uses **Alembic** for database migrations. Migrations run automatically on application startup, but you can also manage them manually.

### Automatic Migrations

When the backend starts, it automatically runs any pending migrations. This ensures the database schema is always up-to-date with the code.

### Manual Migration Commands

```bash
# Run inside the backend container
docker compose exec backend bash

# Check current migration status
alembic current

# Run all pending migrations
alembic upgrade head

# Rollback one migration
alembic downgrade -1

# View migration history
alembic history
```

### Creating New Migrations

When you modify the models in `app/models.py`, create a new migration:

```bash
# Auto-generate migration from model changes
docker compose exec backend alembic revision --autogenerate -m "description_of_change"

# Or create an empty migration for custom SQL
docker compose exec backend alembic revision -m "description_of_change"
```

Then edit the generated file in `backend/alembic/versions/` if needed.

### Migration Files

```
backend/
â”œâ”€â”€ alembic.ini              # Alembic configuration
â””â”€â”€ alembic/
    â”œâ”€â”€ env.py               # Migration environment setup
    â”œâ”€â”€ script.py.mako       # Template for new migrations
    â””â”€â”€ versions/            # Migration scripts
        â”œâ”€â”€ 001_initial.py   # Initial schema
        â””â”€â”€ 002_add_complete_enum.py  # Example migration
```

### Fresh Database Setup

For a completely fresh database, migrations will create all tables automatically:

```bash
# Start only the database
docker compose up -d db

# Run migrations
docker compose exec backend alembic upgrade head
```

## ï¿½ğŸ“– API Documentation

Once the backend is running, visit:
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

### Main Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/v1/auth/register` | Create account |
| `POST` | `/api/v1/auth/login` | Get JWT token |
| `GET` | `/api/v1/fields` | List user's fields |
| `POST` | `/api/v1/fields` | Create a field |
| `POST` | `/api/v1/analysis/{id}` | Run satellite analysis |
| `POST` | `/api/v1/chat` | Chat with AI assistant |
| `GET` | `/api/v1/alerts` | Get user alerts |

## ğŸ§ª Testing

**Backend:**
```bash
cd backend
pytest
```

**Frontend:**
```bash
cd frontend
npm test
```

## ğŸš¢ Deployment

### Using Docker Compose (VPS/Cloud)

```bash
# Build and start in detached mode
docker-compose up -d --build

# View logs
docker-compose logs -f

# Stop
docker-compose down
```

### Environment Variables for Production

Make sure to set secure values:
- Generate `SECRET_KEY`: `openssl rand -base64 32`
- Generate `NEXTAUTH_SECRET`: `openssl rand -base64 32`
- Use a managed PostgreSQL database
- Set proper `CORS_ORIGINS`

## ğŸ“ License

This project was created for the ESA ActInSpace Challenge.

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request
